{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Learning rate\n",
    "\n",
    "The learning rate hyperparameter is one of the most important in the training of a machine learning model. In this notebook, we will see its influence on training a model using Stochastic Gradient Descent."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc14fa1b80cd186d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# make sure the required packages are installed\n",
    "%pip install numpy pandas scikit-learn matplotlib seaborn --quiet\n",
    "\n",
    "# import the required modules\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "import utils\n",
    "\n",
    "random_state = 42"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T07:01:42.870969Z",
     "start_time": "2024-10-01T07:01:41.042994500Z"
    }
   },
   "id": "bc4dc4d290b4222b",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preparation\n",
    "\n",
    "We use the Statistics Online Computational Resource (SOCR) dataset for human heights (inches) and weight (pounds). We load the dataset scale the X values."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "631f0c539617eef4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = utils.load_dataset_from_csv('data/height_weight.csv',\n",
    "                      ['Height'], 'Weight', 0.2, random_state=random_state)\n",
    "# Scale X_train and X_test using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T07:01:42.966160500Z",
     "start_time": "2024-10-01T07:01:42.868486600Z"
    }
   },
   "id": "d21e62bdce6add7c",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Different learning rates\n",
    "\n",
    "We train the model with different learning rates and epochs and show the results of evaluating the model with the test set."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a398c1925f9395c2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum MSE value: 102.477695.\n",
      "Mean Squared Error (MSE) for different learning rates and epochs:\n"
     ]
    },
    {
     "data": {
      "text/plain": "                 1            10          100         1000\n0.0001   10440.323654  1400.982150  102.492753  102.491950\n0.0010     283.518016   102.482946  102.488639  102.488639\n0.0100     102.533908   102.477695  102.477695  102.477695\n0.1000     104.119767   102.665155  102.916523  102.916523\n1.0000     106.680738   102.803322  103.969483  103.969483\n10.0000    465.419403   129.847802  111.682534  111.682534",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>10</th>\n      <th>100</th>\n      <th>1000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0.0001</th>\n      <td>10440.323654</td>\n      <td>1400.982150</td>\n      <td>102.492753</td>\n      <td>102.491950</td>\n    </tr>\n    <tr>\n      <th>0.0010</th>\n      <td>283.518016</td>\n      <td>102.482946</td>\n      <td>102.488639</td>\n      <td>102.488639</td>\n    </tr>\n    <tr>\n      <th>0.0100</th>\n      <td>102.533908</td>\n      <td>102.477695</td>\n      <td>102.477695</td>\n      <td>102.477695</td>\n    </tr>\n    <tr>\n      <th>0.1000</th>\n      <td>104.119767</td>\n      <td>102.665155</td>\n      <td>102.916523</td>\n      <td>102.916523</td>\n    </tr>\n    <tr>\n      <th>1.0000</th>\n      <td>106.680738</td>\n      <td>102.803322</td>\n      <td>103.969483</td>\n      <td>103.969483</td>\n    </tr>\n    <tr>\n      <th>10.0000</th>\n      <td>465.419403</td>\n      <td>129.847802</td>\n      <td>111.682534</td>\n      <td>111.682534</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_mses_for_learning_rates(X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame, y_test: pd.Series,\n",
    "                                    learning_rates: List[float], epochs: List[int]) -> Dict[int, Dict[float, float]]:\n",
    "    \"\"\"\n",
    "    Compute the Mean Squared Error (MSE) for different learning rates and epochs using the SGDRegressor model\n",
    "    :param X_train: The input data (independent variables) for training \n",
    "    :param y_train: The output data (dependent variable) for training \n",
    "    :param X_test: The input data (independent variables) for testing\n",
    "    :param y_test: The output data (dependent variable) for testing\n",
    "    :param learning_rates: The learning different rates to be used\n",
    "    :param epochs: The number of epochs to be used\n",
    "    :return: A dictionary containing the MSE values for each epoch(first key) and learning rate (second key)\n",
    "    \"\"\"\n",
    "    import warnings; warnings.filterwarnings('ignore')  # ignore the warnings for small max_iter values\n",
    "    # Initialize a list to store the MSE values\n",
    "    mse_values_per_n_epochs = dict()\n",
    "    # For each learning rate\n",
    "    for epoch in epochs:\n",
    "        mse_values_per_n_epochs[epoch] = dict()\n",
    "        for learning_rate in learning_rates:\n",
    "            # Create and train the SGDRegressor model\n",
    "            model = SGDRegressor(eta0=learning_rate, max_iter=epoch, random_state=random_state)\n",
    "            model.fit(X_train, y_train)\n",
    "            # Predict the values for the test set\n",
    "            y_pred = model.predict(X_test)\n",
    "            # Compute the Mean Squared Error (MSE) for the test set\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            mse_values_per_n_epochs[epoch][learning_rate] = mse\n",
    "    return mse_values_per_n_epochs\n",
    "\n",
    "\n",
    "# Create and train SDGRegressor models for different learning rates and epochs\n",
    "learning_rates = [0.0001, 0.001, 0.01, 0.1, 1.0, 10]\n",
    "epochs = [1, 10, 100, 1000]\n",
    "mse_values = compute_mses_for_learning_rates(X_train, y_train, X_test, y_test, learning_rates, epochs)\n",
    "# Show the MSE values for each learning rate and epoch\n",
    "table = pd.DataFrame(mse_values)  # row indexes are learning rates, column indexes are epochs, cell values are MSEs\n",
    "print(f\"Minimum MSE value: {table.min().min():.6f}.\")  # The first min() gets the minimum value of each column,\n",
    "                                                       # the second min() gets the minimum value of the resulting Series.\n",
    "print(\"Mean Squared Error (MSE) for different learning rates and epochs:\")\n",
    "table"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T07:01:43.667158500Z",
     "start_time": "2024-10-01T07:01:42.917442900Z"
    }
   },
   "id": "b5759cd51b50bc44",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ✨ Questions ✨\n",
    "\n",
    "The following questions are very important to understand the behavior of the learning rate and training with GD and, in general, of neural networks.\n",
    "1. What happens when the learning rate is too small?\n",
    "2. What happens when the learning rate is too large?\n",
    "3. In general, what happens when the number of epochs is too small? "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb81ee069cce7e6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answers \n",
    "\n",
    "*Write your answers here.*\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10e5febc0fb09b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T07:01:43.682626600Z",
     "start_time": "2024-10-01T07:01:43.663883800Z"
    }
   },
   "id": "8c2924ba47085933",
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
